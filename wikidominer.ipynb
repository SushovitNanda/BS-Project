{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh3-8xmVu64D",
        "outputId": "847ab061-9a98-42fc-9af1-43494304f167"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=d8994d5dcdc226ce0e55d7d947a51dc46a35fe12f33572946bdedd5901ebb9b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y4xj3s7-uOhx"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Define domain and related noun phrases\n",
        "domain = \"health\"\n",
        "noun_phrases = [\n",
        "    \"Preventive care strategies\",\n",
        "    \"Public health policies\",\n",
        "    \"Mental health awareness\",\n",
        "    \"Nutritional supplementation\",\n",
        "    \"Chronic disease management\",\n",
        "    \"Healthcare accessibility\",\n",
        "    \"Medical treatment protocols\",\n",
        "    \"Patient-centered care\"\n",
        "]\n",
        "\n",
        "# Function to fetch Wikipedia content with expanded search\n",
        "def fetch_wikipedia_content(query):\n",
        "    try:\n",
        "        search_results = wikipedia.search(query, results=5)  # Get more related pages\n",
        "        corpus_data = []\n",
        "        for result in search_results:\n",
        "            try:\n",
        "                page = wikipedia.page(result)\n",
        "                corpus_data.append({\"title\": page.title, \"summary\": page.summary, \"content\": page.content})\n",
        "            except wikipedia.exceptions.DisambiguationError as e:\n",
        "                print(f\"Disambiguation error for {result}: {e.options}\")\n",
        "            except wikipedia.exceptions.PageError:\n",
        "                print(f\"Page not found for {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching {result}: {e}\")\n",
        "            time.sleep(1)  # Pause to avoid rate limiting\n",
        "        return corpus_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching for {query}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Extract extended corpus\n",
        "def extract_corpus():\n",
        "    corpus = {}\n",
        "    for phrase in noun_phrases:\n",
        "        print(f\"Fetching related content for: {phrase}\")\n",
        "        data = fetch_wikipedia_content(phrase)\n",
        "        if data:\n",
        "            corpus[phrase] = data\n",
        "        time.sleep(1)  # Pause to avoid rate limiting\n",
        "    return corpus\n",
        "\n",
        "# Save corpus to JSON\n",
        "def save_corpus(corpus, filename=\"health_corpus.json\"):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(corpus, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"Corpus saved to {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    health_corpus = extract_corpus()\n",
        "    save_corpus(health_corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQA77MhJu053",
        "outputId": "f905b162-874f-4980-a537-758498451b41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching related content for: Preventive care strategies\n",
            "Fetching related content for: Public health policies\n",
            "Fetching related content for: Mental health awareness\n",
            "Fetching related content for: Nutritional supplementation\n",
            "Page not found for Parenteral nutrition\n",
            "Disambiguation error for Ensure: ['Entire function', 'Entire (animal)', 'Entire (botany)', 'Entier function']\n",
            "Fetching related content for: Chronic disease management\n",
            "Fetching related content for: Healthcare accessibility\n",
            "Page not found for Generic medicine in India\n",
            "Fetching related content for: Medical treatment protocols\n",
            "Disambiguation error for Medical protocol: ['Medical guideline', 'emergency medical technician', 'Clinical protocol']\n",
            "Fetching related content for: Patient-centered care\n",
            "Corpus saved to health_corpus.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "subxjZBGu_-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}